"use strict";(globalThis.webpackChunkrobolearn=globalThis.webpackChunkrobolearn||[]).push([[8631],{7461:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>r});const s=JSON.parse('{"id":"module-4-humanoid-vla/capstone/21-1-capstone-specification","title":"Lesson 21.1: Capstone Specification","description":"For this capstone, we will define a \\"fetch\\" task for a simulated humanoid robot.","source":"@site/docs/module-4-humanoid-vla/21-capstone/21-1-capstone-specification.md","sourceDirName":"module-4-humanoid-vla/21-capstone","slug":"/module-4-humanoid-vla/capstone/21-1-capstone-specification","permalink":"/robolearn/docs/module-4-humanoid-vla/capstone/21-1-capstone-specification","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammadsaimraza/robolearn/tree/main/docs/module-4-humanoid-vla/21-capstone/21-1-capstone-specification.md","tags":[],"version":"current","frontMatter":{},"sidebar":"textbookSidebar","previous":{"title":"Chapter 21: Module 4 Capstone","permalink":"/robolearn/docs/module-4-humanoid-vla/capstone/"},"next":{"title":"Lesson 21.2: Building the Autonomous Humanoid (High-Level Integration)","permalink":"/robolearn/docs/module-4-humanoid-vla/capstone/21-2-building-the-autonomous-humanoid"}}');var o=i(4848),c=i(8453);const t={},l="Lesson 21.1: Capstone Specification",a={},r=[{value:"High-Level Requirements",id:"high-level-requirements",level:2},{value:"Scenario",id:"scenario",level:2},{value:"System Components",id:"system-components",level:2},{value:"Node-by-Node Specification",id:"node-by-node-specification",level:2},{value:"1. <code>voice_command_node</code>",id:"1-voice_command_node",level:3},{value:"2. <code>llm_planner_node</code>",id:"2-llm_planner_node",level:3},{value:"3. <code>action_executor_node</code>",id:"3-action_executor_node",level:3},{value:"4. Navigation Stack (Nav2 + Isaac ROS VSLAM)",id:"4-navigation-stack-nav2--isaac-ros-vslam",level:3},{value:"5. Perception Stack (Object Detection)",id:"5-perception-stack-object-detection",level:3},{value:"6. Manipulation Stack (MoveIt2)",id:"6-manipulation-stack-moveit2",level:3},{value:"Launch File Specification (<code>humanoid_vla_capstone.launch.py</code>)",id:"launch-file-specification-humanoid_vla_capstonelaunchpy",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,c.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"lesson-211-capstone-specification",children:"Lesson 21.1: Capstone Specification"})}),"\n",(0,o.jsx)(n.p,{children:'For this capstone, we will define a "fetch" task for a simulated humanoid robot.'}),"\n",(0,o.jsx)(n.h2,{id:"high-level-requirements",children:"High-Level Requirements"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"The system shall be capable of receiving a natural language voice command from a human user."}),"\n",(0,o.jsx)(n.li,{children:"The system shall use an LLM to interpret the command and generate a structured plan."}),"\n",(0,o.jsx)(n.li,{children:"The robot shall navigate to a specified location in a simulated environment."}),"\n",(0,o.jsx)(n.li,{children:"The robot shall use its perception system to identify a target object."}),"\n",(0,o.jsx)(n.li,{children:"The robot shall manipulate the object (e.g., pick it up, push it)."}),"\n",(0,o.jsx)(n.li,{children:"The entire system shall be launched with a single command."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"scenario",children:"Scenario"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Robot:"})," A simplified simulated humanoid (e.g., our two-wheeled robot with a camera, LiDAR, and a simple gripper arm added).\n",(0,o.jsx)(n.strong,{children:"Environment:"})," A simulated indoor environment in Isaac Sim with furniture and objects.\n",(0,o.jsx)(n.strong,{children:"Task:"}),' The user says, "Go to the kitchen and bring me the red mug."']}),"\n",(0,o.jsx)(n.h2,{id:"system-components",children:"System Components"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Speech-to-Text Node:"})," Converts human speech to text."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"LLM Planner Node:"})," Interprets text commands, generates JSON plans."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Action Executor Node:"})," Translates JSON plans into ROS 2 actions/services."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Navigation Stack:"})," Uses VSLAM and Nav2 for autonomous movement."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Perception Stack:"})," Uses camera and object detection for finding objects."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Manipulation Stack:"})," Uses MoveIt2 for arm control."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation:"})," Isaac Sim with a humanoid model and a realistic environment."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"node-by-node-specification",children:"Node-by-Node Specification"}),"\n",(0,o.jsxs)(n.h3,{id:"1-voice_command_node",children:["1. ",(0,o.jsx)(n.code,{children:"voice_command_node"})]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose:"})," Captures audio, sends to STT, publishes text."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Topics Published:"})," ",(0,o.jsx)(n.code,{children:"/voice_command_text"})," (",(0,o.jsx)(n.code,{children:"std_msgs/msg/String"}),")."]}),"\n"]}),"\n",(0,o.jsxs)(n.h3,{id:"2-llm_planner_node",children:["2. ",(0,o.jsx)(n.code,{children:"llm_planner_node"})]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose:"})," Subscribes to text commands, prompts LLM, publishes JSON plan."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Topics Subscribed:"})," ",(0,o.jsx)(n.code,{children:"/voice_command_text"})," (",(0,o.jsx)(n.code,{children:"std_msgs/msg/String"}),")."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Topics Published:"})," ",(0,o.jsx)(n.code,{children:"/robot_plan"})," (",(0,o.jsx)(n.code,{children:"std_msgs/msg/String"})," - containing JSON)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Behavior:"})," Uses a pre-defined prompt to query an external LLM API (e.g., OpenAI, Gemini)."]}),"\n"]}),"\n",(0,o.jsxs)(n.h3,{id:"3-action_executor_node",children:["3. ",(0,o.jsx)(n.code,{children:"action_executor_node"})]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose:"})," Subscribes to JSON plans, calls appropriate ROS 2 actions/services."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Topics Subscribed:"})," ",(0,o.jsx)(n.code,{children:"/robot_plan"})," (",(0,o.jsx)(n.code,{children:"std_msgs/msg/String"}),")."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Services Called:"})," Nav2 ",(0,o.jsx)(n.code,{children:"/navigate_to_pose"}),", MoveIt2 ",(0,o.jsx)(n.code,{children:"/move_group/action"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Behavior:"})," Parses JSON, orchestrates calls to navigation, perception, and manipulation."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"4-navigation-stack-nav2--isaac-ros-vslam",children:"4. Navigation Stack (Nav2 + Isaac ROS VSLAM)"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose:"})," Autonomous movement to target locations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Inputs:"})," Camera, IMU data (from Isaac Sim). Goal pose (from ",(0,o.jsx)(n.code,{children:"action_executor_node"}),")."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Outputs:"})," ",(0,o.jsx)(n.code,{children:"/cmd_vel"})," (",(0,o.jsx)(n.code,{children:"geometry_msgs/msg/Twist"}),")."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"5-perception-stack-object-detection",children:"5. Perception Stack (Object Detection)"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose:"})," Locates specified objects."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Inputs:"})," Camera data (from Isaac Sim)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Services Provided:"})," ",(0,o.jsx)(n.code,{children:"/find_object"})," (",(0,o.jsx)(n.code,{children:"my_custom_interfaces/srv/FindObject"}),")."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Behavior:"})," Runs a pre-trained object detection model."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"6-manipulation-stack-moveit2",children:"6. Manipulation Stack (MoveIt2)"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose:"})," Plans and executes arm movements for grasping."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Inputs:"})," Target object pose (from ",(0,o.jsx)(n.code,{children:"action_executor_node"}),")."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Services Provided:"})," ",(0,o.jsx)(n.code,{children:"/pickup_object"})," (",(0,o.jsx)(n.code,{children:"my_custom_interfaces/srv/PickupObject"}),")."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Behavior:"})," Uses MoveIt2 to plan and execute a grasp."]}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"launch-file-specification-humanoid_vla_capstonelaunchpy",children:["Launch File Specification (",(0,o.jsx)(n.code,{children:"humanoid_vla_capstone.launch.py"}),")"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Start Isaac Sim."}),"\n",(0,o.jsx)(n.li,{children:"Spawn the humanoid robot model."}),"\n",(0,o.jsxs)(n.li,{children:["Launch ",(0,o.jsx)(n.code,{children:"voice_command_node"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Launch ",(0,o.jsx)(n.code,{children:"llm_planner_node"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Launch ",(0,o.jsx)(n.code,{children:"action_executor_node"}),"."]}),"\n",(0,o.jsx)(n.li,{children:"Launch Nav2 stack (including VSLAM, local and global planners)."}),"\n",(0,o.jsx)(n.li,{children:"Launch object detection node."}),"\n",(0,o.jsx)(n.li,{children:"Launch MoveIt2 planning and execution nodes."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"This is a comprehensive system. While the full implementation is beyond the scope of this lesson, the specification lays out the entire architecture. In the next lessons, we'll focus on the high-level integration points."})]})}function h(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(6540);const o={},c=s.createContext(o);function t(e){const n=s.useContext(c);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(c.Provider,{value:n},e.children)}}}]);