"use strict";(globalThis.webpackChunkrobolearn=globalThis.webpackChunkrobolearn||[]).push([[1171],{7764:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"textbookSidebar":[{"type":"category","label":"MODULE 1: ROS","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"1. PHYSICAL AI","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/physical-ai/1-1-digital-to-physical","label":"Lesson 1.1: From Digital to Physical","docId":"module-1-ros/physical-ai/1-1-digital-to-physical","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/physical-ai/1-2-embodied-intelligence","label":"Lesson 1.2: Embodied Intelligence","docId":"module-1-ros/physical-ai/1-2-embodied-intelligence","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/physical-ai/1-3-humanoid-revolution","label":"Lesson 1.3: The Humanoid Revolution","docId":"module-1-ros/physical-ai/1-3-humanoid-revolution","unlisted":false}],"href":"/robolearn/docs/module-1-ros/physical-ai/"},{"type":"category","label":"2. ROBOT SYSTEM","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/robot-system/2-1-how-robots-see","label":"Lesson 2.1: How Robots See (Sensors)","docId":"module-1-ros/robot-system/2-1-how-robots-see","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/robot-system/2-2-how-robots-move","label":"Lesson 2.2: How Robots Move (Actuators)","docId":"module-1-ros/robot-system/2-2-how-robots-move","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/robot-system/2-3-why-middleware-exists","label":"Lesson 2.3: Why Middleware Exists","docId":"module-1-ros/robot-system/2-3-why-middleware-exists","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/robot-system/2-4-your-hardware-tier","label":"Lesson 2.4: Your Hardware Tier","docId":"module-1-ros/robot-system/2-4-your-hardware-tier","unlisted":false}],"href":"/robolearn/docs/module-1-ros/robot-system/"},{"type":"category","label":"3. MEET ROS2","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/meet-ros2/3-1-environment-setup","label":"Lesson 3.1: Environment Setup","docId":"module-1-ros/meet-ros2/3-1-environment-setup","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/meet-ros2/3-2-turtlesim","label":"Lesson 3.2: Your First Robot (Turtlesim)","docId":"module-1-ros/meet-ros2/3-2-turtlesim","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/meet-ros2/3-3-nodes-and-topic","label":"Lesson 3.3: Nodes & Topics","docId":"module-1-ros/meet-ros2/3-3-nodes-and-topic","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/meet-ros2/3-4-services-and-parameters","label":"Lesson 3.4: Services & Parameters","docId":"module-1-ros/meet-ros2/3-4-services-and-parameters","unlisted":false}],"href":"/robolearn/docs/module-1-ros/meet-ros2/"},{"type":"category","label":"4. FIRST CODE","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/first-code/4-1-workspaces-and-packages","label":"Lesson 4.1: Workspaces & Packages","docId":"module-1-ros/first-code/4-1-workspaces-and-packages","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/first-code/4-2-writing-publisher","label":"Lesson 4.2: Writing a Publisher","docId":"module-1-ros/first-code/4-2-writing-publisher","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/first-code/4-3-writing-subscriber","label":"Lesson 4.3: Writing a Subscriber","docId":"module-1-ros/first-code/4-3-writing-subscriber","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/first-code/4-4-try-with-ai","label":"Lesson 4.4: Try With AI","docId":"module-1-ros/first-code/4-4-try-with-ai","unlisted":false}],"href":"/robolearn/docs/module-1-ros/first-code/"},{"type":"category","label":"5. COMMUNICATION","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/communication/5-1-service-server","label":"Lesson 5.1: Service Server","docId":"module-1-ros/communication/5-1-service-server","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/communication/5-2-service-clients","label":"Lesson 5.2: Service Client","docId":"module-1-ros/communication/5-2-service-clients","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/communication/5-3-custom-interface","label":"Lesson 5.3: Custom Interfaces","docId":"module-1-ros/communication/5-3-custom-interface","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/communication/5-4-design-patterns","label":"Lesson 5.4: Design Patterns (Topics vs. Services)","docId":"module-1-ros/communication/5-4-design-patterns","unlisted":false}],"href":"/robolearn/docs/module-1-ros/communication/"},{"type":"category","label":"6. BUILDING SYSTEMS","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/building-systems/6-1-parameters","label":"Lesson 6.1: Parameters","docId":"module-1-ros/building-systems/6-1-parameters","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/building-systems/6-2-launch-files","label":"Lesson 6.2: Launch Files","docId":"module-1-ros/building-systems/6-2-launch-files","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/building-systems/6-3-debugging-systems","label":"Lesson 6.3: Debugging Systems","docId":"module-1-ros/building-systems/6-3-debugging-systems","unlisted":false}],"href":"/robolearn/docs/module-1-ros/building-systems/"},{"type":"category","label":"7. CAPSTONE","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-1-ros/capstone/7-1-capstone-specification","label":"Lesson 7.1: The Specification","docId":"module-1-ros/capstone/7-1-capstone-specification","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/capstone/7-2-building-the-controller","label":"Lesson 7.2: Building the Controller","docId":"module-1-ros/capstone/7-2-building-the-controller","unlisted":false},{"type":"link","href":"/robolearn/docs/module-1-ros/capstone/7-3-testing-and-validation","label":"Lesson 7.3: Testing & Validation","docId":"module-1-ros/capstone/7-3-testing-and-validation","unlisted":false}],"href":"/robolearn/docs/module-1-ros/capstone/"}],"href":"/robolearn/docs/module-1-ros/"},{"type":"category","label":"MODULE 2: SIMULATION","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"8. WHY SIMULATE","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-2-simulation/why-simulate/8-1-digital-twin-concept","label":"Lesson 8.1: The Digital Twin Concept","docId":"module-2-simulation/why-simulate/8-1-digital-twin-concept","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/why-simulate/8-2-simulation-first","label":"Lesson 8.2: Simulation-First Development","docId":"module-2-simulation/why-simulate/8-2-simulation-first","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/why-simulate/8-3-meet-gazebo","label":"Lesson 8.3: Meet Gazebo","docId":"module-2-simulation/why-simulate/8-3-meet-gazebo","unlisted":false}],"href":"/robolearn/docs/module-2-simulation/why-simulate/"},{"type":"category","label":"9. ROBOT DESCRIPTION FORMATS","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-2-simulation/robot-description-formats/9-1-understanding-urdf","label":"Lesson 9.1: Understanding URDF","docId":"module-2-simulation/robot-description-formats/9-1-understanding-urdf","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/robot-description-formats/9-2-building-first-robot","label":"Lesson 9.2: Building Your First Robot","docId":"module-2-simulation/robot-description-formats/9-2-building-first-robot","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/robot-description-formats/9-3-physical-properties","label":"Lesson 9.3: Physical Properties","docId":"module-2-simulation/robot-description-formats/9-3-physical-properties","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/robot-description-formats/9-4-urdf-with-ai","label":"Lesson 9.4: URDF with AI","docId":"module-2-simulation/robot-description-formats/9-4-urdf-with-ai","unlisted":false}],"href":"/robolearn/docs/module-2-simulation/robot-description-formats/"},{"type":"category","label":"10. BUILDING IN SIMULATION","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-2-simulation/building-in-simulation/10-1-sdf-world-basics","label":"Lesson 10.1: SDF World Basics","docId":"module-2-simulation/building-in-simulation/10-1-sdf-world-basics","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/building-in-simulation/10-2-models-from-fuel","label":"Lesson 10.2: Models from Fuel","docId":"module-2-simulation/building-in-simulation/10-2-models-from-fuel","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/building-in-simulation/10-3-physical-configuration","label":"Lesson 10.3: Physical Configuration (Gazebo-Specific Tags)","docId":"module-2-simulation/building-in-simulation/10-3-physical-configuration","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/building-in-simulation/10-4-world-building-with-ai","label":"Lesson 10.4: World Building with AI","docId":"module-2-simulation/building-in-simulation/10-4-world-building-with-ai","unlisted":false}],"href":"/robolearn/docs/module-2-simulation/building-in-simulation/"},{"type":"category","label":"11. SENSORS IN SIMULATION","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-2-simulation/sensors-in-simulation/11-1-camera-simulation","label":"Lesson 11.1: Camera Simulation","docId":"module-2-simulation/sensors-in-simulation/11-1-camera-simulation","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/sensors-in-simulation/11-2-lidar-simulation","label":"Lesson 11.2: LiDAR Simulation","docId":"module-2-simulation/sensors-in-simulation/11-2-lidar-simulation","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/sensors-in-simulation/11-3-imu-and-contact","label":"Lesson 11.3: IMU & Contact Sensors","docId":"module-2-simulation/sensors-in-simulation/11-3-imu-and-contact","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/sensors-in-simulation/11-4-sensors-debugging","label":"Lesson 11.4: Sensors Debugging","docId":"module-2-simulation/sensors-in-simulation/11-4-sensors-debugging","unlisted":false}],"href":"/robolearn/docs/module-2-simulation/sensors-in-simulation/"},{"type":"category","label":"12. ROS2 + GAZEBO INTEGRATION","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-2-simulation/ros2-gazebo-integration/12-1-ros-gz-bridge","label":"Lesson 12.1: The ros_gz_bridge","docId":"module-2-simulation/ros2-gazebo-integration/12-1-ros-gz-bridge","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/ros2-gazebo-integration/12-2-spawning-robots","label":"Lesson 12.2: Spawning Robots (Review)","docId":"module-2-simulation/ros2-gazebo-integration/12-2-spawning-robots","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/ros2-gazebo-integration/12-3-closed-loop-control","label":"Lesson 12.3: Closed-Loop Control","docId":"module-2-simulation/ros2-gazebo-integration/12-3-closed-loop-control","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/ros2-gazebo-integration/12-4-creating-skills","label":"Lesson 12.4: Creating Skills","docId":"module-2-simulation/ros2-gazebo-integration/12-4-creating-skills","unlisted":false}],"href":"/robolearn/docs/module-2-simulation/ros2-gazebo-integration/"},{"type":"category","label":"13. MODULE 2 CAPSTONE","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-2-simulation/module-2-capstone/13-1-capstone-specification","label":"Lesson 13.1: The Specification","docId":"module-2-simulation/module-2-capstone/13-1-capstone-specification","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/module-2-capstone/13-2-building-the-simulation","label":"Lesson 13.2: Building the Simulation","docId":"module-2-simulation/module-2-capstone/13-2-building-the-simulation","unlisted":false},{"type":"link","href":"/robolearn/docs/module-2-simulation/module-2-capstone/13-3-testing-and-validation","label":"Lesson 13.3: Testing & Validation","docId":"module-2-simulation/module-2-capstone/13-3-testing-and-validation","unlisted":false}],"href":"/robolearn/docs/module-2-simulation/module-2-capstone/"}],"href":"/robolearn/docs/module-2-simulation/"},{"type":"category","label":"3. NVIDIA Isaac Platform","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 14: Introduction to NVIDIA Isaac","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/intro-to-isaac/14-1-the-isaac-ecosystem","label":"Lesson 14.1: The Isaac Ecosystem","docId":"module-3-nvidia-isaac/intro-to-isaac/14-1-the-isaac-ecosystem","unlisted":false},{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/intro-to-isaac/14-2-isaac-sim-vs-gazebo","label":"Lesson 14.2: Isaac Sim vs. Gazebo","docId":"module-3-nvidia-isaac/intro-to-isaac/14-2-isaac-sim-vs-gazebo","unlisted":false}],"href":"/robolearn/docs/module-3-nvidia-isaac/intro-to-isaac/"},{"type":"category","label":"Chapter 15: Isaac Sim & Synthetic Data","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/isaac-sim/15-1-synthetic-data-generation","label":"Lesson 15.1: Synthetic Data Generation","docId":"module-3-nvidia-isaac/isaac-sim/15-1-synthetic-data-generation","unlisted":false},{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/isaac-sim/15-2-domain-randomization","label":"Lesson 15.2: Domain Randomization","docId":"module-3-nvidia-isaac/isaac-sim/15-2-domain-randomization","unlisted":false}],"href":"/robolearn/docs/module-3-nvidia-isaac/isaac-sim/"},{"type":"category","label":"Chapter 16: Isaac ROS & GPU-Accelerated Perception","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/isaac-ros/16-1-the-need-for-speed-gpu-acceleration","label":"Lesson 16.1: The Need for Speed: GPU Acceleration","docId":"module-3-nvidia-isaac/isaac-ros/16-1-the-need-for-speed-gpu-acceleration","unlisted":false},{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/isaac-ros/16-2-isaac-ros-vslam","label":"Lesson 16.2: Isaac ROS VSLAM","docId":"module-3-nvidia-isaac/isaac-ros/16-2-isaac-ros-vslam","unlisted":false}],"href":"/robolearn/docs/module-3-nvidia-isaac/isaac-ros/"},{"type":"category","label":"Chapter 17: Sim-to-Real","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/sim-to-real/17-1-the-reality-gap","label":"Lesson 17.1: The Reality Gap","docId":"module-3-nvidia-isaac/sim-to-real/17-1-the-reality-gap","unlisted":false},{"type":"link","href":"/robolearn/docs/module-3-nvidia-isaac/sim-to-real/17-2-bridging-the-gap","label":"Lesson 17.2: Bridging the Gap","docId":"module-3-nvidia-isaac/sim-to-real/17-2-bridging-the-gap","unlisted":false}],"href":"/robolearn/docs/module-3-nvidia-isaac/sim-to-real/"}],"href":"/robolearn/docs/module-3-nvidia-isaac/"},{"type":"category","label":"4. Humanoid VLA Systems","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 18: Humanoid Kinematics & Dynamics","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/kinematics-dynamics/18-1-kinematics-the-geometry-of-motion","label":"Lesson 18.1: Kinematics: The Geometry of Motion","docId":"module-4-humanoid-vla/kinematics-dynamics/18-1-kinematics-the-geometry-of-motion","unlisted":false},{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/kinematics-dynamics/18-2-dynamics-the-physics-of-motion","label":"Lesson 18.2: Dynamics: The Physics of Motion","docId":"module-4-humanoid-vla/kinematics-dynamics/18-2-dynamics-the-physics-of-motion","unlisted":false}],"href":"/robolearn/docs/module-4-humanoid-vla/kinematics-dynamics/"},{"type":"category","label":"Chapter 19: Motion Planning for Manipulation","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/motion-planning/19-1-what-is-motion-planning","label":"Lesson 19.1: What is Motion Planning?","docId":"module-4-humanoid-vla/motion-planning/19-1-what-is-motion-planning","unlisted":false},{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/motion-planning/19-2-introduction-to-moveit2","label":"Lesson 19.2: Introduction to MoveIt2","docId":"module-4-humanoid-vla/motion-planning/19-2-introduction-to-moveit2","unlisted":false}],"href":"/robolearn/docs/module-4-humanoid-vla/motion-planning/"},{"type":"category","label":"Chapter 20: Conversational Robotics & VLAs","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/conversational-robotics/20-1-voice-to-action-pipeline","label":"Lesson 20.1: The Voice-to-Action Pipeline","docId":"module-4-humanoid-vla/conversational-robotics/20-1-voice-to-action-pipeline","unlisted":false},{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/conversational-robotics/20-2-llm-cognitive-planning","label":"Lesson 20.2: LLM Cognitive Planning","docId":"module-4-humanoid-vla/conversational-robotics/20-2-llm-cognitive-planning","unlisted":false}],"href":"/robolearn/docs/module-4-humanoid-vla/conversational-robotics/"},{"type":"category","label":"Chapter 21: Module 4 Capstone","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/capstone/21-1-capstone-specification","label":"Lesson 21.1: Capstone Specification","docId":"module-4-humanoid-vla/capstone/21-1-capstone-specification","unlisted":false},{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/capstone/21-2-building-the-autonomous-humanoid","label":"Lesson 21.2: Building the Autonomous Humanoid (High-Level Integration)","docId":"module-4-humanoid-vla/capstone/21-2-building-the-autonomous-humanoid","unlisted":false},{"type":"link","href":"/robolearn/docs/module-4-humanoid-vla/capstone/21-3-testing-and-validation","label":"Lesson 21.3: Testing & Validation","docId":"module-4-humanoid-vla/capstone/21-3-testing-and-validation","unlisted":false}],"href":"/robolearn/docs/module-4-humanoid-vla/capstone/"}],"href":"/robolearn/docs/module-4-humanoid-vla/"},{"type":"link","href":"/robolearn/docs/Introduction/","label":"Welcome to RoboLearn","docId":"Introduction/introduction","unlisted":false}]},"docs":{"Introduction/introduction":{"id":"Introduction/introduction","title":"Welcome to RoboLearn","description":"Physical AI & Humanoid Robotics: Bridging the Digital Brain and the Physical Body","sidebar":"textbookSidebar"},"module-1-ros/building-systems/6-1-parameters":{"id":"module-1-ros/building-systems/6-1-parameters","title":"Lesson 6.1: Parameters","description":"Hard-coding values inside your code is generally a bad practice. What if you want to change the timer rate of your talker node? Or change the chatter topic to whisper? You could edit the code and rebuild, but there\'s a much better way: Parameters.","sidebar":"textbookSidebar"},"module-1-ros/building-systems/6-2-launch-files":{"id":"module-1-ros/building-systems/6-2-launch-files","title":"Lesson 6.2: Launch Files","description":"So far, every time you\'ve wanted to run your talker/listener system, you\'ve had to open two terminals, source the environment in both, and run a ros2 run command in each. This is tedious and doesn\'t scale.","sidebar":"textbookSidebar"},"module-1-ros/building-systems/6-3-debugging-systems":{"id":"module-1-ros/building-systems/6-3-debugging-systems","title":"Lesson 6.3: Debugging Systems","description":"When you have a dozen nodes all started from a launch file, how do you figure out what\'s going on? If something isn\'t working, where do you start? ROS 2 provides several powerful tools for inspecting and debugging a live system.","sidebar":"textbookSidebar"},"module-1-ros/building-systems/index":{"id":"module-1-ros/building-systems/index","title":"Chapter 6: Building Robot Systems","description":"You can now write individual ROS 2 nodes that communicate using topics and services. But a real robot is not one or two nodes; it\'s a complex system of dozens of nodes all working together. How do you start, configure, and manage such a system?","sidebar":"textbookSidebar"},"module-1-ros/capstone/7-1-capstone-specification":{"id":"module-1-ros/capstone/7-1-capstone-specification","title":"Lesson 7.1: The Specification","description":"Before writing a single line of code for a complex system, a good engineer writes a specification. A specification is a detailed description of what the system should do, not how it should do it. It defines the components, their interfaces, and their expected behavior.","sidebar":"textbookSidebar"},"module-1-ros/capstone/7-2-building-the-controller":{"id":"module-1-ros/capstone/7-2-building-the-controller","title":"Lesson 7.2: Building the Controller","description":"With a clear specification, the coding becomes much more straightforward. We are no longer designing on the fly; we are simply implementing the plan we\'ve already made.","sidebar":"textbookSidebar"},"module-1-ros/capstone/7-3-testing-and-validation":{"id":"module-1-ros/capstone/7-3-testing-and-validation","title":"Lesson 7.3: Testing & Validation","description":"Your system is built and running. Now, how do you know if it works? You must test it against the requirements laid out in your specification.","sidebar":"textbookSidebar"},"module-1-ros/capstone/index":{"id":"module-1-ros/capstone/index","title":"Chapter 7: Capstone - Robot Controller","description":"Welcome to the capstone project for Module 1. In this chapter, you will put everything you have learned\u2014nodes, topics, services, parameters, and launch files\u2014together to build a complete, multi-node robot controller system for Turtlesim.","sidebar":"textbookSidebar"},"module-1-ros/communication/5-1-service-server":{"id":"module-1-ros/communication/5-1-service-server","title":"Lesson 5.1: Service Server","description":"A ROS 2 Service is a request/response communication pattern. A server node advertises a service, and a client node can call that service. The client then waits for the server to send back a response.","sidebar":"textbookSidebar"},"module-1-ros/communication/5-2-service-clients":{"id":"module-1-ros/communication/5-2-service-clients","title":"Lesson 5.2: Service Client","description":"Calling a service from the command line is useful for testing, but in a real robot, you\'ll have another node that acts as the client. The client is responsible for sending the request and waiting for the response.","sidebar":"textbookSidebar"},"module-1-ros/communication/5-3-custom-interface":{"id":"module-1-ros/communication/5-3-custom-interface","title":"Lesson 5.3: Custom Interfaces","description":"So far, we have used built-in message and service types like stdmsgs/msg/String and exampleinterfaces/srv/AddTwoInts. But for any real robot, you will need to define your own data structures. In ROS 2, these are called interfaces.","sidebar":"textbookSidebar"},"module-1-ros/communication/5-4-design-patterns":{"id":"module-1-ros/communication/5-4-design-patterns","title":"Lesson 5.4: Design Patterns (Topics vs. Services)","description":"You are now armed with two powerful communication tools: topics (publish/subscribe) and services (request/response). The mark of an experienced ROS developer is knowing which tool to use for which job. This is a question of system design.","sidebar":"textbookSidebar"},"module-1-ros/communication/index":{"id":"module-1-ros/communication/index","title":"Chapter 5: Communication Mastery","description":"You\'ve mastered the publish/subscribe pattern, the one-to-many broadcast mechanism that forms the backbone of ROS 2. But what happens when you need a two-way conversation? What if you need to guarantee that a request was received and get a direct response?","sidebar":"textbookSidebar"},"module-1-ros/first-code/4-1-workspaces-and-packages":{"id":"module-1-ros/first-code/4-1-workspaces-and-packages","title":"Lesson 4.1: Workspaces & Packages","description":"Before we write code, we need to organize our files. ROS 2 has a standard, conventional structure for development called a workspace.","sidebar":"textbookSidebar"},"module-1-ros/first-code/4-2-writing-publisher":{"id":"module-1-ros/first-code/4-2-writing-publisher","title":"Lesson 4.2: Writing a Publisher","description":"Let\'s write our first real ROS 2 node. We\'ll create a \\"talker\\" node that publishes a simple string message to a topic at a regular interval.","sidebar":"textbookSidebar"},"module-1-ros/first-code/4-3-writing-subscriber":{"id":"module-1-ros/first-code/4-3-writing-subscriber","title":"Lesson 4.3: Writing a Subscriber","description":"A publisher isn\'t very useful on its own. We need another node to receive the messages. In this lesson, you will create a \\"listener\\" node that subscribes to the chatter topic and prints the messages it receives.","sidebar":"textbookSidebar"},"module-1-ros/first-code/4-4-try-with-ai":{"id":"module-1-ros/first-code/4-4-try-with-ai","title":"Lesson 4.4: Try With AI","description":"You\'ve now written a publisher and a subscriber manually. You understand the components: the node class, the createpublisher/createsubscription calls, the callbacks, and the rclpy.spin() loop.","sidebar":"textbookSidebar"},"module-1-ros/first-code/index":{"id":"module-1-ros/first-code/index","title":"Chapter 4: Your First ROS 2 Code","description":"You\'ve explored ROS 2 from the command line. Now it\'s time to write your own nodes. In this chapter, you will transition from being a ROS user to a ROS developer. You will learn how to structure your code into workspaces and packages, and you will write your first Python publisher and subscriber nodes.","sidebar":"textbookSidebar"},"module-1-ros/index":{"id":"module-1-ros/index","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"Welcome to the foundation of your Physical AI journey. Over the next 5 weeks, you\'ll bridge the gap between software AI (like ChatGPT) and embodied intelligence (robots that move and act in the physical world). You\'ll explore why robots are fundamentally different from software, understand the hardware and middleware that makes robotics possible, and gain hands-on experience with ROS 2\u2014the middleware that powers professional robotics systems worldwide.","sidebar":"textbookSidebar"},"module-1-ros/meet-ros2/3-1-environment-setup":{"id":"module-1-ros/meet-ros2/3-1-environment-setup","title":"Lesson 3.1: Environment Setup","description":"Before you can interact with a ROS 2 system, you need access to one. In this lesson, you will get your environment up and running.","sidebar":"textbookSidebar"},"module-1-ros/meet-ros2/3-2-turtlesim":{"id":"module-1-ros/meet-ros2/3-2-turtlesim","title":"Lesson 3.2: Your First Robot (Turtlesim)","description":"Turtlesim is a simple, lightweight robot simulator that is part of the standard ROS 2 installation. It is the \\"Hello, World!\\" of robotics. While it may seem basic, it\'s the perfect tool for learning the core concepts of ROS 2 without the complexity of a full 3D simulator.","sidebar":"textbookSidebar"},"module-1-ros/meet-ros2/3-3-nodes-and-topic":{"id":"module-1-ros/meet-ros2/3-3-nodes-and-topic","title":"Lesson 3.3: Nodes & Topics","description":"In the last lesson, you got Turtlesim running. You have a turtlesimnode process and a turtleteleop_key process. But from the perspective of ROS, these are just generic processes. Let\'s use the ros2 CLI to see what\'s really going on.","sidebar":"textbookSidebar"},"module-1-ros/meet-ros2/3-4-services-and-parameters":{"id":"module-1-ros/meet-ros2/3-4-services-and-parameters","title":"Lesson 3.4: Services & Parameters","description":"Topics are great for continuous streams of data, but sometimes you need a request/response interaction. For example, \\"What is the current time?\\" or \\"Please reset the simulation.\\" This is what Services are for.","sidebar":"textbookSidebar"},"module-1-ros/meet-ros2/index":{"id":"module-1-ros/meet-ros2/index","title":"Chapter 3: Meet ROS 2","description":"The theory is over. It\'s time to get your hands dirty. In this chapter, you will set up your ROS 2 environment and take your first steps into the world of robotics middleware. You won\'t be writing any Python code just yet. Instead, you\'ll use the powerful ros2 command-line interface (CLI) to explore a live ROS 2 system, control a simulated robot, and inspect how different components communicate with each other.","sidebar":"textbookSidebar"},"module-1-ros/physical-ai/1-1-digital-to-physical":{"id":"module-1-ros/physical-ai/1-1-digital-to-physical","title":"Lesson 1.1: From Digital to Physical","description":"Welcome to the first lesson in your journey to understanding Physical AI. You\'ve likely interacted with many forms of Digital AI. Think of ChatGPT, DALL-E, or even the recommendation algorithm on your favorite streaming service. These are powerful systems, but they exist in a world of pure information. They process data, and they output data. Their reality is instantaneous, their environment is perfectly controlled, and the laws of physics do not apply to them.","sidebar":"textbookSidebar"},"module-1-ros/physical-ai/1-2-embodied-intelligence":{"id":"module-1-ros/physical-ai/1-2-embodied-intelligence","title":"Lesson 1.2: Embodied Intelligence","description":"In the last lesson, we established that putting an AI in a body subjects it to the harsh realities of the physical world. But the body is not just a prison. In a crucial twist, the robot\'s physical form\u2014its morphology\u2014is a fundamental part of its intelligence.","sidebar":"textbookSidebar"},"module-1-ros/physical-ai/1-3-humanoid-revolution":{"id":"module-1-ros/physical-ai/1-3-humanoid-revolution","title":"Lesson 1.3: The Humanoid Revolution","description":"The dream of creating a human-like robot is as old as automation itself. For decades, it has been the stuff of science fiction. But in the last few years, a convergence of breakthroughs in AI, simulation, and hardware has triggered a \\"Humanoid Revolution.\\"","sidebar":"textbookSidebar"},"module-1-ros/physical-ai/index":{"id":"module-1-ros/physical-ai/index","title":"Chapter 1: What is Physical AI?","description":"You\'re familiar with software AI\u2014ChatGPT that responds in milliseconds, image generators that create instantly, language models that process text at the speed of computation. But what happens when you put AI in a body? When a robot must navigate gravity, deal with latency, move precious metal and motors, and operate in a world that doesn\'t pause for computation?","sidebar":"textbookSidebar"},"module-1-ros/robot-system/2-1-how-robots-see":{"id":"module-1-ros/robot-system/2-1-how-robots-see","title":"Lesson 2.1: How Robots See (Sensors)","description":"A robot\'s understanding of the world is only as good as the data it receives. Sensors are the hardware components that convert physical phenomena from the environment into electrical signals that the robot\'s brain can process. They are the robot\'s eyes, ears, and sense of balance.","sidebar":"textbookSidebar"},"module-1-ros/robot-system/2-2-how-robots-move":{"id":"module-1-ros/robot-system/2-2-how-robots-move","title":"Lesson 2.2: How Robots Move (Actuators)","description":"If sensors are how a robot perceives the world, actuators are how it affects the world. An actuator is a device that converts an electrical signal into physical motion. They are the muscles of the robot.","sidebar":"textbookSidebar"},"module-1-ros/robot-system/2-3-why-middleware-exists":{"id":"module-1-ros/robot-system/2-3-why-middleware-exists","title":"Lesson 2.3: Why Middleware Exists","description":"We\'ve seen that a robot has many sensors (cameras, IMUs, encoders) and many actuators (motors). We also know that it has software components for higher-level reasoning, like path planning and object recognition.","sidebar":"textbookSidebar"},"module-1-ros/robot-system/2-4-your-hardware-tier":{"id":"module-1-ros/robot-system/2-4-your-hardware-tier","title":"Lesson 2.4: Your Hardware Tier","description":"This course is designed to be accessible to a wide range of students, from those with just a laptop to those with a full robotics lab. To accommodate this, we have defined four \\"Hardware Tiers.\\"","sidebar":"textbookSidebar"},"module-1-ros/robot-system/index":{"id":"module-1-ros/robot-system/index","title":"Chapter 2: The Robot System","description":"In Chapter 1, we explored the \\"why\\" of Physical AI. Now, we dive into the \\"how.\\" A robot is a complex system of hardware and software working in concert. This chapter breaks down that system into its fundamental components. You\'ll learn how robots perceive the world (sensors), how they affect it (actuators), and the critical role of the software that connects them (middleware).","sidebar":"textbookSidebar"},"module-2-simulation/building-in-simulation/10-1-sdf-world-basics":{"id":"module-2-simulation/building-in-simulation/10-1-sdf-world-basics","title":"Lesson 10.1: SDF World Basics","description":"An SDF file is an XML file that describes a simulation world. Let\'s create a simple, empty world with just a light source and a ground plane.","sidebar":"textbookSidebar"},"module-2-simulation/building-in-simulation/10-2-models-from-fuel":{"id":"module-2-simulation/building-in-simulation/10-2-models-from-fuel","title":"Lesson 10.2: Models from Fuel","description":"Building every object in your world from scratch would be time-consuming. Fortunately, Gazebo has access to a large online database of pre-made models called the Ignition Fuel marketplace. You can browse it at app.ignitionrobotics.org.","sidebar":"textbookSidebar"},"module-2-simulation/building-in-simulation/10-3-physical-configuration":{"id":"module-2-simulation/building-in-simulation/10-3-physical-configuration","title":"Lesson 10.3: Physical Configuration (Gazebo-Specific Tags)","description":"URDF is a general-purpose format, but simulators often need more information than it can provide. To solve this, we can add Gazebo-specific tags to our URDF file inside a `` block. The simulator will read these tags, but other ROS tools will simply ignore them.","sidebar":"textbookSidebar"},"module-2-simulation/building-in-simulation/10-4-world-building-with-ai":{"id":"module-2-simulation/building-in-simulation/10-4-world-building-with-ai","title":"Lesson 10.4: World Building with AI","description":"Just as with URDF, writing complex SDF world files by hand can be tedious. You can use an AI assistant to quickly generate interesting and complex worlds for your robot to train and test in.","sidebar":"textbookSidebar"},"module-2-simulation/building-in-simulation/index":{"id":"module-2-simulation/building-in-simulation/index","title":"Chapter 10: Building in Simulation","description":"You have a model of your robot. Now you need a world for it to live in. In Gazebo, a world is defined using the Simulation Description Format (SDF).","sidebar":"textbookSidebar"},"module-2-simulation/index":{"id":"module-2-simulation/index","title":"Module 2: Simulation","description":"Welcome to Module 2. In the first module, you mastered the \\"nervous system\\" of your robot with ROS 2. Now, you will give that nervous system a body and a world to live in\u2014a Digital Twin.","sidebar":"textbookSidebar"},"module-2-simulation/module-2-capstone/13-1-capstone-specification":{"id":"module-2-simulation/module-2-capstone/13-1-capstone-specification","title":"Lesson 13.1: The Specification","description":"As in the Module 1 capstone, we begin by writing a clear and unambiguous technical specification.","sidebar":"textbookSidebar"},"module-2-simulation/module-2-capstone/13-2-building-the-simulation":{"id":"module-2-simulation/module-2-capstone/13-2-building-the-simulation","title":"Lesson 13.2: Building the Simulation","description":"This lesson involves assembling the pieces of the simulation based on our specification. You will create the world, ensure your URDF is complete, and write the final launch file.","sidebar":"textbookSidebar"},"module-2-simulation/module-2-capstone/13-3-testing-and-validation":{"id":"module-2-simulation/module-2-capstone/13-3-testing-and-validation","title":"Lesson 13.3: Testing & Validation","description":"Your integrated system is running. Now it\'s time to validate its performance against our specification from Lesson 13.1.","sidebar":"textbookSidebar"},"module-2-simulation/module-2-capstone/index":{"id":"module-2-simulation/module-2-capstone/index","title":"Chapter 13: Module 2 Capstone","description":"Welcome to the capstone project for Module 2. You have learned how to model a robot, build a world, add sensors, and create closed-loop controllers. Now you will put it all together to create a complete, simulated autonomous system.","sidebar":"textbookSidebar"},"module-2-simulation/robot-description-formats/9-1-understanding-urdf":{"id":"module-2-simulation/robot-description-formats/9-1-understanding-urdf","title":"Lesson 9.1: Understanding URDF","description":"The Unified Robot Description Format (URDF) is an XML-based file format for representing a robot model. At its core, a URDF file describes the robot as a tree of links and joints.","sidebar":"textbookSidebar"},"module-2-simulation/robot-description-formats/9-2-building-first-robot":{"id":"module-2-simulation/robot-description-formats/9-2-building-first-robot","title":"Lesson 9.2: Building Your First Robot","description":"Let\'s apply the concepts from the last lesson to build a simple, two-wheeled mobile robot in URDF. Our robot will have:","sidebar":"textbookSidebar"},"module-2-simulation/robot-description-formats/9-3-physical-properties":{"id":"module-2-simulation/robot-description-formats/9-3-physical-properties","title":"Lesson 9.3: Physical Properties","description":"Your robot looks right in RViz, but as far as a physics engine is concerned, it\'s a ghost. It has no mass, no friction, and no substance. To simulate the robot in a tool like Gazebo, we need to add its physical properties.","sidebar":"textbookSidebar"},"module-2-simulation/robot-description-formats/9-4-urdf-with-ai":{"id":"module-2-simulation/robot-description-formats/9-4-urdf-with-ai","title":"Lesson 9.4: URDF with AI","description":"Writing URDF files manually is tedious and error-prone. The XML syntax is verbose, and calculating transforms and inertia tensors can be tricky. This is another area where an AI assistant can be a powerful collaborator.","sidebar":"textbookSidebar"},"module-2-simulation/robot-description-formats/index":{"id":"module-2-simulation/robot-description-formats/index","title":"Chapter 9: Robot Description Formats","description":"How do you tell a simulator what your robot looks like? How do you describe its shape, its joints, and how they connect? You need a standard format. In the ROS ecosystem, the most common format for this is the Unified Robot Description Format (URDF).","sidebar":"textbookSidebar"},"module-2-simulation/ros2-gazebo-integration/12-1-ros-gz-bridge":{"id":"module-2-simulation/ros2-gazebo-integration/12-1-ros-gz-bridge","title":"Lesson 12.1: The ros_gz_bridge","description":"Gazebo and ROS are two separate, independent systems. Gazebo has its own internal publish/subscribe system called \\"Gazebo Transport.\\" ROS has its own publish/subscribe system (DDS). They do not speak the same language.","sidebar":"textbookSidebar"},"module-2-simulation/ros2-gazebo-integration/12-2-spawning-robots":{"id":"module-2-simulation/ros2-gazebo-integration/12-2-spawning-robots","title":"Lesson 12.2: Spawning Robots (Review)","description":"We briefly covered this in Chapter 10, but it\'s worth looking at the mechanism for adding your robot to the simulation in more detail.","sidebar":"textbookSidebar"},"module-2-simulation/ros2-gazebo-integration/12-3-closed-loop-control":{"id":"module-2-simulation/ros2-gazebo-integration/12-3-closed-loop-control","title":"Lesson 12.3: Closed-Loop Control","description":"So far, our control has been open-loop. We publish a velocity command and just hope the robot does what we want. We are not using any sensor feedback to adjust our commands.","sidebar":"textbookSidebar"},"module-2-simulation/ros2-gazebo-integration/12-4-creating-skills":{"id":"module-2-simulation/ros2-gazebo-integration/12-4-creating-skills","title":"Lesson 12.4: Creating Skills","description":"The \\"wall follower\\" you built in the last lesson is an example of a skill or a behavior. It\'s a self-contained ROS 2 node (or collection of nodes) that accomplishes a specific, reusable task.","sidebar":"textbookSidebar"},"module-2-simulation/ros2-gazebo-integration/index":{"id":"module-2-simulation/ros2-gazebo-integration/index","title":"Chapter 12: ROS 2 + Gazebo Integration","description":"You have a simulated robot in a simulated world, and you have a collection of ROS 2 nodes. How do you get them to talk to each other?","sidebar":"textbookSidebar"},"module-2-simulation/sensors-in-simulation/11-1-camera-simulation":{"id":"module-2-simulation/sensors-in-simulation/11-1-camera-simulation","title":"Lesson 11.1: Camera Simulation","description":"A camera is the richest sensor in robotics, providing the data needed for object detection, navigation, and interaction. Let\'s add a camera to our two-wheeled robot.","sidebar":"textbookSidebar"},"module-2-simulation/sensors-in-simulation/11-2-lidar-simulation":{"id":"module-2-simulation/sensors-in-simulation/11-2-lidar-simulation","title":"Lesson 11.2: LiDAR Simulation","description":"LiDAR (Light Detection and Ranging) is a critical sensor for navigation and obstacle avoidance. It provides a precise 2D or 3D scan of the environment by measuring the distance to objects with laser beams.","sidebar":"textbookSidebar"},"module-2-simulation/sensors-in-simulation/11-3-imu-and-contact":{"id":"module-2-simulation/sensors-in-simulation/11-3-imu-and-contact","title":"Lesson 11.3: IMU & Contact Sensors","description":"Let\'s round out our sensor suite with two more important types: an IMU for balance and orientation, and a contact sensor to detect collisions.","sidebar":"textbookSidebar"},"module-2-simulation/sensors-in-simulation/11-4-sensors-debugging":{"id":"module-2-simulation/sensors-in-simulation/11-4-sensors-debugging","title":"Lesson 11.4: Sensors Debugging","description":"Your simulation is now publishing a lot of data. But how do you know if the data is correct? Debugging simulated sensors is a critical skill. Here are the primary tools and techniques you should use.","sidebar":"textbookSidebar"},"module-2-simulation/sensors-in-simulation/index":{"id":"module-2-simulation/sensors-in-simulation/index","title":"Chapter 11: Sensors in Simulation","description":"A robot is blind without its sensors. A key advantage of a simulator like Gazebo is the ability to model a wide variety of sensors and have them produce realistic data, just as a physical sensor would.","sidebar":"textbookSidebar"},"module-2-simulation/why-simulate/8-1-digital-twin-concept":{"id":"module-2-simulation/why-simulate/8-1-digital-twin-concept","title":"Lesson 8.1: The Digital Twin Concept","description":"A Digital Twin is a virtual model of a physical object or system. It is not just a static 3D model; it is a dynamic, living simulation that is updated with real-world data and can be used to model the behavior of its physical counterpart.","sidebar":"textbookSidebar"},"module-2-simulation/why-simulate/8-2-simulation-first":{"id":"module-2-simulation/why-simulate/8-2-simulation-first","title":"Lesson 8.2: Simulation-First Development","description":"The existence of high-fidelity digital twins has led to a paradigm shift in how robotics software is developed. This is the \\"Simulation-First\\" workflow.","sidebar":"textbookSidebar"},"module-2-simulation/why-simulate/8-3-meet-gazebo":{"id":"module-2-simulation/why-simulate/8-3-meet-gazebo","title":"Lesson 8.3: Meet Gazebo","description":"There are many robotics simulators, but for the open-source robotics community, Gazebo has been the dominant tool for over a decade.","sidebar":"textbookSidebar"},"module-2-simulation/why-simulate/index":{"id":"module-2-simulation/why-simulate/index","title":"Chapter 8: Why Simulate?","description":"Before we dive into building our simulated world, it\'s worth asking: why do we bother? Why not just work with the physical robot from day one? This chapter explores the philosophy and practice of simulation in modern robotics, from the concept of a Digital Twin to the \\"Simulation-First\\" development workflow that powers today\'s leading robotics companies.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/index":{"id":"module-3-nvidia-isaac/index","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","description":"Welcome to Module 3. You\'ve mastered the fundamentals of ROS 2 and learned how to build and test robots in a physics simulator. Now, it\'s time to give your robot an AI-powered brain.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/intro-to-isaac/14-1-the-isaac-ecosystem":{"id":"module-3-nvidia-isaac/intro-to-isaac/14-1-the-isaac-ecosystem","title":"Lesson 14.1: The Isaac Ecosystem","description":"NVIDIA Isaac is not a single product; it\'s a collection of tools designed to address the entire robotics development pipeline, from simulation and training to deployment and execution.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/intro-to-isaac/14-2-isaac-sim-vs-gazebo":{"id":"module-3-nvidia-isaac/intro-to-isaac/14-2-isaac-sim-vs-gazebo","title":"Lesson 14.2: Isaac Sim vs. Gazebo","description":"You\'ve spent the last module learning Gazebo. Now we are introducing a new simulator, Isaac Sim. What\'s the difference? When would you choose one over the other?","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/intro-to-isaac/index":{"id":"module-3-nvidia-isaac/intro-to-isaac/index","title":"Chapter 14: Introduction to NVIDIA Isaac","description":"This chapter provides a high-level overview of the NVIDIA Isaac platform, the professional-grade toolkit for AI robotics development. You will learn about the different components of the Isaac ecosystem and how they fit together to help developers build, train, and deploy intelligent robots.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/isaac-ros/16-1-the-need-for-speed-gpu-acceleration":{"id":"module-3-nvidia-isaac/isaac-ros/16-1-the-need-for-speed-gpu-acceleration","title":"Lesson 16.1: The Need for Speed: GPU Acceleration","description":"A CPU (Central Processing Unit) is a general-purpose processor. It has a few very fast, very smart cores that are designed to execute sequential tasks one after another.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/isaac-ros/16-2-isaac-ros-vslam":{"id":"module-3-nvidia-isaac/isaac-ros/16-2-isaac-ros-vslam","title":"Lesson 16.2: Isaac ROS VSLAM","description":"SLAM (Simultaneous Localization and Mapping) is one of the most fundamental problems in mobile robotics. It is the process of building a map of an unknown environment while simultaneously keeping track of the robot\'s position within that map.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/isaac-ros/index":{"id":"module-3-nvidia-isaac/isaac-ros/index","title":"Chapter 16: Isaac ROS & GPU-Accelerated Perception","description":"You\'ve trained a model on synthetic data. Now you need to run it on your robot. The challenge is that many modern perception algorithms, like Visual SLAM or object detection with large neural networks, are too computationally expensive to run in real-time on a robot\'s CPU.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/isaac-sim/15-1-synthetic-data-generation":{"id":"module-3-nvidia-isaac/isaac-sim/15-1-synthetic-data-generation","title":"Lesson 15.1: Synthetic Data Generation","description":"Training a modern deep learning model for a task like object detection requires a huge amount of labeled data. For example, the COCO dataset, a common benchmark, has over 200,000 labeled images. Creating such a dataset by hand\u2014taking pictures and then manually drawing bounding boxes around every object\u2014is incredibly slow and expensive.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/isaac-sim/15-2-domain-randomization":{"id":"module-3-nvidia-isaac/isaac-sim/15-2-domain-randomization","title":"Lesson 15.2: Domain Randomization","description":"If you train an AI model exclusively on perfectly clean, beautifully rendered synthetic data, it will perform very well in the simulator. But when you deploy it to a physical robot in the real world, it will likely fail. This is the \\"sim-to-real\\" gap.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/isaac-sim/index":{"id":"module-3-nvidia-isaac/isaac-sim/index","title":"Chapter 15: Isaac Sim & Synthetic Data","description":"This chapter dives into the primary use case for Isaac Sim: generating high-quality, labeled data for training AI perception models. You will learn how Isaac Sim\'s Replicator tool can be used to create massive datasets with perfect ground truth, and how Domain Randomization can be applied to ensure the resulting models work in the real world.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/sim-to-real/17-1-the-reality-gap":{"id":"module-3-nvidia-isaac/sim-to-real/17-1-the-reality-gap","title":"Lesson 17.1: The Reality Gap","description":"You have trained a brilliant object detection model on 1 million synthetic images from Isaac Sim. It achieves 99.9% accuracy in the simulator. You deploy it to your physical robot, point it at a real coffee mug, and... it sees nothing. What happened?","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/sim-to-real/17-2-bridging-the-gap":{"id":"module-3-nvidia-isaac/sim-to-real/17-2-bridging-the-gap","title":"Lesson 17.2: Bridging the Gap","description":"Overcoming the sim-to-real gap is one of the most active areas of research in robotics today. There is no single magic bullet, but a collection of powerful techniques that, when used together, can be highly effective.","sidebar":"textbookSidebar"},"module-3-nvidia-isaac/sim-to-real/index":{"id":"module-3-nvidia-isaac/sim-to-real/index","title":"Chapter 17: Sim-to-Real","description":"This chapter addresses the most critical challenge in modern, AI-driven robotics: transferring knowledge from the clean, predictable world of the simulator to the messy, unpredictable real world. This is the Sim-to-Real problem.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/capstone/21-1-capstone-specification":{"id":"module-4-humanoid-vla/capstone/21-1-capstone-specification","title":"Lesson 21.1: Capstone Specification","description":"For this capstone, we will define a \\"fetch\\" task for a simulated humanoid robot.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/capstone/21-2-building-the-autonomous-humanoid":{"id":"module-4-humanoid-vla/capstone/21-2-building-the-autonomous-humanoid","title":"Lesson 21.2: Building the Autonomous Humanoid (High-Level Integration)","description":"Building the full autonomous humanoid outlined in the specification involves integrating a large number of complex components. This lesson focuses on how you would connect these pieces at a high level.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/capstone/21-3-testing-and-validation":{"id":"module-4-humanoid-vla/capstone/21-3-testing-and-validation","title":"Lesson 21.3: Testing & Validation","description":"Testing an autonomous humanoid robot system, especially one driven by natural language and AI, is a complex undertaking. It requires a systematic approach to ensure all components are functioning correctly and that the integrated system meets its high-level requirements.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/capstone/index":{"id":"module-4-humanoid-vla/capstone/index","title":"Chapter 21: Module 4 Capstone","description":"Welcome to the grand finale of this course. In this capstone project, you will integrate everything you have learned across all four modules to build an Autonomous Humanoid capable of understanding natural language commands and executing them in a simulated physical environment.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/conversational-robotics/20-1-voice-to-action-pipeline":{"id":"module-4-humanoid-vla/conversational-robotics/20-1-voice-to-action-pipeline","title":"Lesson 20.1: The Voice-to-Action Pipeline","description":"The ultimate goal of many robotics applications is to create a robot that can naturally interact with humans, understanding complex instructions and executing them in the physical world. The Voice-to-Action (V2A) Pipeline is the framework for achieving this.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/conversational-robotics/20-2-llm-cognitive-planning":{"id":"module-4-humanoid-vla/conversational-robotics/20-2-llm-cognitive-planning","title":"Lesson 20.2: LLM Cognitive Planning","description":"The heart of the Voice-to-Action pipeline is the LLM Cognitive Planner. This is where the robot truly \\"understands\\" the human\'s intent and translates it into a sequence of executable robot actions.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/conversational-robotics/index":{"id":"module-4-humanoid-vla/conversational-robotics/index","title":"Chapter 20: Conversational Robotics & VLAs","description":"This chapter brings together the power of Large Language Models (LLMs) with robot perception and action. You will learn to build Vision-Language-Action (VLA) systems that allow a robot to understand natural language commands and translate them into physical actions.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/index":{"id":"module-4-humanoid-vla/index","title":"Module 4: Humanoid VLA Systems","description":"Welcome to the final and most advanced module of this course. You have built the nervous system (ROS 2), the body and world (Gazebo), and the AI brain (Isaac). Now, you will put them all together to create a Vision-Language-Action (VLA) system for a humanoid robot.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/kinematics-dynamics/18-1-kinematics-the-geometry-of-motion":{"id":"module-4-humanoid-vla/kinematics-dynamics/18-1-kinematics-the-geometry-of-motion","title":"Lesson 18.1: Kinematics: The Geometry of Motion","description":"Kinematics is the \\"geometry of motion.\\" It\'s a mathematical framework for describing the position, orientation, and velocity of the robot\'s body parts without considering the forces involved. For a robot arm or leg, there are two fundamental kinematic problems.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/kinematics-dynamics/18-2-dynamics-the-physics-of-motion":{"id":"module-4-humanoid-vla/kinematics-dynamics/18-2-dynamics-the-physics-of-motion","title":"Lesson 18.2: Dynamics: The Physics of Motion","description":"Kinematics describes how a robot can move. Dynamics describes why it moves. It is the study of motion in relation to the forces, torques, and energy that produce it.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/kinematics-dynamics/index":{"id":"module-4-humanoid-vla/kinematics-dynamics/index","title":"Chapter 18: Humanoid Kinematics & Dynamics","description":"A humanoid robot has a complex, multi-jointed body. To make it move, we must first understand the mathematics that governs its geometry and motion. This chapter introduces the two core disciplines for this: kinematics and dynamics.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/motion-planning/19-1-what-is-motion-planning":{"id":"module-4-humanoid-vla/motion-planning/19-1-what-is-motion-planning","title":"Lesson 19.1: What is Motion Planning?","description":"Motion planning is the process of finding a valid sequence of movements to get a robot from a starting configuration to a goal configuration. It seems simple, but it is a computationally very hard problem.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/motion-planning/19-2-introduction-to-moveit2":{"id":"module-4-humanoid-vla/motion-planning/19-2-introduction-to-moveit2","title":"Lesson 19.2: Introduction to MoveIt2","description":"MoveIt is the most widely used software for motion planning in the ROS ecosystem. It is a large and complex framework that provides everything you need to get a robot arm moving.","sidebar":"textbookSidebar"},"module-4-humanoid-vla/motion-planning/index":{"id":"module-4-humanoid-vla/motion-planning/index","title":"Chapter 19: Motion Planning for Manipulation","description":"Knowing where you want your robot\'s hand to go (the IK solution) is only the first step. Motion Planning is the process of figuring out how to get there. It is the problem of finding a valid, collision-free path for the robot\'s arm from its current configuration to a target configuration.","sidebar":"textbookSidebar"}}}}')}}]);