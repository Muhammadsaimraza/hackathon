# سبق 21.1: کیپسٹون تفصیلات

اس کیپسٹون کے لیے، ہم ایک سمیولیٹڈ ہیومنائڈ روبوٹ کے لیے "فیچ" ٹاسک کی وضاحت کریں گے۔

## اعلیٰ سطحی ضروریات

1.  نظام ایک انسانی صارف سے قدرتی زبان کی صوتی کمانڈ وصول کرنے کے قابل ہوگا۔
2.  نظام کمانڈ کی تشریح کرنے اور ایک سٹرکچرڈ پلان تیار کرنے کے لیے LLM کا استعمال کرے گا۔
3.  روبوٹ ایک سمیولیٹڈ ماحول میں ایک مخصوص مقام پر نیویگیٹ کرے گا۔
4.  روبوٹ ہدف آبجیکٹ کی شناخت کے لیے اپنے پرسیپشن سسٹم کا استعمال کرے گا۔
5.  روبوٹ آبجیکٹ کو مینیپولٹ کرے گا (مثلاً، اسے اٹھانا، اسے دھکیلنا)۔
6.  پورا نظام ایک ہی کمانڈ سے لانچ کیا جائے گا۔

## منظرنامہ

**روبوٹ:** ایک سادہ سمیولیٹڈ ہیومنائڈ (مثلاً، کیمرہ، LiDAR، اور ایک سادہ گریپر بازو کے ساتھ ہمارا دو پہیوں والا روبوٹ)۔
**ماحول:** Isaac Sim میں فرنیچر اور اشیاء کے ساتھ ایک سمیولیٹڈ اندرونی ماحول۔
**کام:** صارف کہتا ہے، "کچن میں جاؤ اور مجھے سرخ مگ لاؤ۔"

## سسٹم کے اجزاء

1.  **اسپیچ-ٹو-ٹیکسٹ نوڈ:** انسانی تقریر کو ٹیکسٹ میں تبدیل کرتا ہے۔
2.  **LLM پلانر نوڈ:** ٹیکسٹ کمانڈز کی تشریح کرتا ہے، JSON پلانز تیار کرتا ہے۔
3.  **ایکشن ایگزیکیوٹر نوڈ:** JSON پلانز کو ROS 2 ایکشنز/سروسز میں ترجمہ کرتا ہے۔
4.  **نیویگیشن اسٹیک:** خود مختار حرکت کے لیے VSLAM اور Nav2 کا استعمال کرتا ہے۔
5.  **پرسیپشن اسٹیک:** اشیاء کو تلاش کرنے کے لیے کیمرہ اور آبجیکٹ ڈیٹیکشن کا استعمال کرتا ہے۔
6.  **مینیپولیشن اسٹیک:** بازو کنٹرول کے لیے MoveIt2 کا استعمال کرتا ہے۔
7.  **سیمولیشن:** ایک ہیومنائڈ ماڈل اور ایک حقیقت پسندانہ ماحول کے ساتھ Isaac Sim۔

## نوڈ بہ نوڈ تفصیلات

### 1. `voice_command_node`
*   **مقصد:** آڈیو کیپچر کرتا ہے، STT کو بھیجتا ہے، ٹیکسٹ شائع کرتا ہے۔
*   **شائع کردہ ٹاپکس:** `/voice_command_text` (`std_msgs/msg/String`)۔

### 2. `llm_planner_node`
*   **مقصد:** ٹیکسٹ کمانڈز کو سبسکرائب کرتا ہے، LLM کو پرامپٹ کرتا ہے، JSON پلان شائع کرتا ہے۔
*   **سبسکرائب کردہ ٹاپکس:** `/voice_command_text` (`std_msgs/msg/String`)۔
*   **شائع کردہ ٹاپکس:** `/robot_plan` (`std_msgs/msg/String` - JSON پر مشتمل)۔
*   **رویہ:** ایک بیرونی LLM API (مثلاً، OpenAI، Gemini) کو استفسار کرنے کے لیے ایک پہلے سے بیان کردہ پرامپٹ کا استعمال کرتا ہے۔

### 3. `action_executor_node`
*   **مقصد:** JSON پلانز کو سبسکرائب کرتا ہے، مناسب ROS 2 ایکشنز/سروسز کو کال کرتا ہے۔
*   **سبسکرائب کردہ ٹاپکس:** `/robot_plan` (`std_msgs/msg/String`)۔
*   **کال کردہ خدمات:** Nav2 `/navigate_to_pose`، MoveIt2 `/move_group/action`۔
*   **رویہ:** JSON کو پارس کرتا ہے، نیویگیشن، پرسیپشن، اور مینیپولیشن کو کالز کو منظم کرتا ہے۔

### 4. نیویگیشن اسٹیک (Nav2 + Isaac ROS VSLAM)
*   **مقصد:** ہدف کے مقامات پر خود مختار حرکت۔
*   **ان پٹ:** کیمرہ، IMU ڈیٹا (Isaac Sim سے)۔ ہدف پوز (`action_executor_node` سے)۔
*   **آؤٹ پٹ:** `/cmd_vel` (`geometry_msgs/msg/Twist`)۔

### 5. پرسیپشن اسٹیک (آبجیکٹ ڈیٹیکشن)
*   **مقصد:** مخصوص اشیاء کو تلاش کرتا ہے۔
*   **ان پٹ:** کیمرہ ڈیٹا (Isaac Sim سے)۔
*   **فراہم کردہ خدمات:** `/find_object` (`my_custom_interfaces/srv/FindObject`)۔
*   **رویہ:** ایک پہلے سے تربیت یافتہ آبجیکٹ ڈیٹیکشن ماڈل چلاتا ہے۔

### 6. مینیپولیشن اسٹیک (MoveIt2)
*   **مقصد:** گرفت کے لیے بازو کی حرکات کی منصوبہ بندی اور عمل درآمد۔
*   **ان پٹ:** ہدف آبجیکٹ پوز (`action_executor_node` سے)۔
*   **فراہم کردہ خدمات:** `/pickup_object` (`my_custom_interfaces/srv/PickupObject`)۔
*   **رویہ:** گرفت کی منصوبہ بندی اور عمل درآمد کے لیے MoveIt2 کا استعمال کرتا ہے۔

## لانچ فائل کی تفصیلات (`humanoid_vla_capstone.launch.py`)

*   Isaac Sim شروع کریں۔
*   ہیومنائڈ روبوٹ ماڈل اسپان کریں۔
*   `voice_command_node` لانچ کریں۔
*   `llm_planner_node` لانچ کریں۔
*   `action_executor_node` لانچ کریں۔
*   Nav2 اسٹیک لانچ کریں (بشمول VSLAM، لوکل اور گلوبل پلانرز)۔
*   آبجیکٹ ڈیٹیکشن نوڈ لانچ کریں۔
*   MoveIt2 پلاننگ اور ایگزیکیوشن نوڈس لانچ کریں۔

یہ ایک جامع نظام ہے۔ جب کہ مکمل عمل درآمد اس سبق کے دائرہ کار سے باہر ہے، تفصیلات پورے فن تعمیر کو واضح کرتی ہے۔ اگلے اسباق میں، ہم اعلیٰ سطحی انٹیگریشن پوائنٹس پر توجہ مرکوز کریں گے۔
