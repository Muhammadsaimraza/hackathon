"use strict";(globalThis.webpackChunkrobolearn=globalThis.webpackChunkrobolearn||[]).push([[4620],{4741:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-2-simulation/sensors-in-simulation/11-1-camera-simulation","title":"Lesson 11.1: Camera Simulation","description":"A camera is the richest sensor in robotics, providing the data needed for object detection, navigation, and interaction. Let\'s add a camera to our two-wheeled robot.","source":"@site/docs/module-2-simulation/11-sensors-in-simulation/11-1-camera-simulation.md","sourceDirName":"module-2-simulation/11-sensors-in-simulation","slug":"/module-2-simulation/sensors-in-simulation/11-1-camera-simulation","permalink":"/hackathon/docs/module-2-simulation/sensors-in-simulation/11-1-camera-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammadsaimraza/docs/module-2-simulation/11-sensors-in-simulation/11-1-camera-simulation.md","tags":[],"version":"current","frontMatter":{},"sidebar":"textbookSidebar","previous":{"title":"Chapter 11: Sensors in Simulation","permalink":"/hackathon/docs/module-2-simulation/sensors-in-simulation/"},"next":{"title":"Lesson 11.2: LiDAR Simulation","permalink":"/hackathon/docs/module-2-simulation/sensors-in-simulation/11-2-lidar-simulation"}}');var s=i(4848),o=i(8453);const r={},t="Lesson 11.1: Camera Simulation",l={},c=[{value:"1. Add a Camera Link",id:"1-add-a-camera-link",level:2},{value:"2. Add the Gazebo Camera Plugin",id:"2-add-the-gazebo-camera-plugin",level:2},{value:"Breakdown",id:"breakdown",level:3},{value:"3. Visualizing the Camera Feed",id:"3-visualizing-the-camera-feed",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"lesson-111-camera-simulation",children:"Lesson 11.1: Camera Simulation"})}),"\n",(0,s.jsx)(n.p,{children:"A camera is the richest sensor in robotics, providing the data needed for object detection, navigation, and interaction. Let's add a camera to our two-wheeled robot."}),"\n",(0,s.jsx)(n.p,{children:"A sensor in Gazebo needs two things:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["A ",(0,s.jsx)(n.code,{children:"<link>"})," to attach it to."]}),"\n",(0,s.jsxs)(n.li,{children:["A ",(0,s.jsx)(n.code,{children:"<sensor>"})," tag within a ",(0,s.jsx)(n.code,{children:"<gazebo>"})," block to define the plugin and its properties."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"1-add-a-camera-link",children:"1. Add a Camera Link"}),"\n",(0,s.jsx)(n.p,{children:"First, we need a physical link for the camera. Let's add a small box to the front of our chassis."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Add to your URDF file --\x3e\n\n\x3c!-- Camera Link --\x3e\n<link name="camera_link">\n  <visual>\n    <geometry>\n      <box size="0.05 0.05 0.05"/>\n    </geometry>\n    <material name="red">\n      <color rgba="1.0 0.0 0.0 1.0"/>\n    </material>\n  </visual>\n  <collision>\n      <geometry>\n          <box size="0.05 0.05 0.05"/>\n      </geometry>\n  </collision>\n  <inertial>\n      <mass value="0.01"/>\n      <inertia ixx="1e-6" ixy="0.0" ixz="0.0" iyy="1e-6" iyyy="0.0" izz="1e-6"/>\n  </inertial>\n</link>\n\n\x3c!-- Camera Joint --\x3e\n<joint name="camera_joint" type="fixed">\n  <parent link="chassis"/>\n  <child link="camera_link"/>\n  <origin xyz="0.225 0 0.075" rpy="0 0 0"/>\n</joint>\n'})}),"\n",(0,s.jsxs)(n.p,{children:["We've created a small red box and attached it to the front of the chassis (",(0,s.jsx)(n.code,{children:"x=0.225"})," is half the chassis length, ",(0,s.jsx)(n.code,{children:"z=0.075"})," is half the chassis height plus half the camera height)."]}),"\n",(0,s.jsx)(n.h2,{id:"2-add-the-gazebo-camera-plugin",children:"2. Add the Gazebo Camera Plugin"}),"\n",(0,s.jsxs)(n.p,{children:["Now, we add the ",(0,s.jsx)(n.code,{children:"<gazebo>"})," tag to attach the camera sensor ",(0,s.jsxs)(n.em,{children:["to the ",(0,s.jsx)(n.code,{children:"camera_link"})]}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Add to your URDF file --\x3e\n\n<gazebo reference="camera_link">\n  <sensor name="camera_sensor" type="camera">\n    <update_rate>30.0</update_rate>\n    <camera name="head">\n      <horizontal_fov>1.3962634</horizontal_fov>\n      <image>\n        <width>800</width>\n        <height>800</height>\n        <format>R8G8B8</format>\n      </image>\n      <clip>\n        <near>0.02</near>\n        <far>300</far>\n      </clip>\n    </camera>\n    <plugin name="camera_controller" filename="libgz-sim-ros2-camera-system.so">\n      <topic_name>image_raw</topic_name>\n      <camera_info_topic_name>camera_info</camera_info_topic_name>\n      <frame_name>camera_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"breakdown",children:"Breakdown"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:'<gazebo reference="camera_link">'})}),": Associates this block with the ",(0,s.jsx)(n.code,{children:"camera_link"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:'<sensor type="camera">'})}),": Defines the sensor."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"<update_rate>"})}),": 30 frames per second."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"<camera>"})," block"]}),": Defines the camera's intrinsic properties.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<horizontal_fov>"}),": The horizontal field of view in radians (1.396 rad = 80 deg)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<image>"}),": The resolution and pixel format."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<clip>"}),": The near and far clipping planes."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"<plugin>"})}),": This is the most important part.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'filename="libgz-sim-ros2-camera-system.so"'}),": This specifies the Gazebo plugin that simulates a camera and publishes its images to ROS 2."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<topic_name>"}),": The ROS 2 topic to publish the images on. We'll use ",(0,s.jsx)(n.code,{children:"image_raw"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<frame_name>"}),": The TF frame to associate with the image data, which should be the link the sensor is attached to."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"3-visualizing-the-camera-feed",children:"3. Visualizing the Camera Feed"}),"\n",(0,s.jsxs)(n.p,{children:["Now, rebuild and launch your ",(0,s.jsx)(n.code,{children:"gazebo.launch.py"}),". Your robot will spawn with the red camera box on top."]}),"\n",(0,s.jsxs)(n.p,{children:["To see the camera data, you need to use another ROS 2 tool: ",(0,s.jsx)(n.strong,{children:"RViz"})," or ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"rqt_image_view"})}),"."]}),"\n",(0,s.jsx)(n.p,{children:"In a new terminal, run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 run rqt_image_view rqt_image_view\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will open a GUI window. In the topic dropdown at the top, select ",(0,s.jsx)(n.code,{children:"/image_raw"}),". You should now see a real-time video feed from the perspective of your simulated robot!"]}),"\n",(0,s.jsxs)(n.p,{children:["Drive the robot around using ",(0,s.jsx)(n.code,{children:"ros2 topic pub"})," commands to the ",(0,s.jsx)(n.code,{children:"/cmd_vel"})," topic, and you will see the image in ",(0,s.jsx)(n.code,{children:"rqt_image_view"})," update."]}),"\n",(0,s.jsx)(n.p,{children:"You have successfully given your robot vision. In the next lesson, you'll give it another powerful sense: LiDAR."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>t});var a=i(6540);const s={},o=a.createContext(s);function r(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);